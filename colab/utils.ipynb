{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d374cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5817c54",
   "metadata": {
    "cell_marker": "# ###############################################################################",
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    " The MIT License (MIT)\n",
    " Copyright (c) 2023 Philippe Ostiguy\n",
    "\n",
    " Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " of this software and associated documentation files (the \"Software\"), to deal\n",
    " in the Software without restriction, including without limitation the rights\n",
    " to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " copies of the Software, and to permit persons to whom the Software is\n",
    " furnished to do so, subject to the following conditions:\n",
    "\n",
    " The above copyright notice and this permission notice shall be included in\n",
    " all copies or substantial portions of the Software.\n",
    "\n",
    " THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    " EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    " MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n",
    " IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n",
    " DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n",
    " OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE\n",
    " OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbe6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_market_calendars as mcal\n",
    "from datetime import datetime, timedelta\n",
    "from pytz import timezone, UTC\n",
    "from functools import lru_cache\n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "from darts import TimeSeries\n",
    "\n",
    "from mean_reversion.config.constants import (\n",
    "    RAW_ATTRIBUTES,\n",
    ")\n",
    "\n",
    "from typing import Optional, Union\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def numpy_to_python(data):\n",
    "    if isinstance(data, dict):\n",
    "        return {k: numpy_to_python(v) for k, v in data.items()}\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        return data.tolist()\n",
    "    elif isinstance(data, (np.float32, np.float64)):\n",
    "        return float(data)\n",
    "    elif isinstance(data, (np.int32, np.int64)):\n",
    "        return int(data)\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def save_json(file: str, data: dict) -> None:\n",
    "    data = numpy_to_python(data)\n",
    "    with open(file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "def read_json(file: str) -> dict:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def create_file_if_not_exist(file: str) -> None:\n",
    "    if not os.path.exists(file):\n",
    "        with open(file, \"w\", encoding=\"utf-8\"):\n",
    "            pass\n",
    "\n",
    "\n",
    "def string_to_datetime(string_to_convert: str) -> datetime:\n",
    "    return datetime.strptime(string_to_convert, \"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def utc_to_est_str(utc_timestamp: int) -> str:\n",
    "    utc_dt = datetime.utcfromtimestamp(utc_timestamp)\n",
    "    est_tz = timezone(\"US/Eastern\")\n",
    "    est_dt = utc_dt.astimezone(est_tz)\n",
    "    return est_dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def est_dt_to_epoch(dt: datetime) -> int:\n",
    "    est = timezone(\"US/Eastern\")\n",
    "    localized_dt = est.localize(dt)\n",
    "    utc_dt = localized_dt.astimezone(UTC)\n",
    "    return int(utc_dt.timestamp())\n",
    "\n",
    "\n",
    "def obtain_market_dates(start_date: str, end_date: str) -> pd.DataFrame:\n",
    "    nyse = mcal.get_calendar(\"NYSE\")\n",
    "    market_open_dates = nyse.schedule(\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "    )\n",
    "    return market_open_dates\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def get_previous_market_date(date, last_market_date=None):\n",
    "    nyse = mcal.get_calendar(\"NYSE\")\n",
    "    if last_market_date is None:\n",
    "        start_date = date - timedelta(days=30)\n",
    "    else:\n",
    "        start_date = last_market_date\n",
    "    market_open_dates = nyse.valid_days(start_date=start_date, end_date=date)\n",
    "    if market_open_dates.empty:\n",
    "        raise ValueError(\n",
    "            f\"No valid NYSE market date found within the previous 60 days from the given date {date}\"\n",
    "        )\n",
    "    last_market_date = market_open_dates[-1].date()\n",
    "    return last_market_date, market_open_dates[-1].date()\n",
    "\n",
    "\n",
    "def read_csv_to_pd_formatted(\n",
    "    file: str,\n",
    "    sort_by_column_name: Optional[str] = RAW_ATTRIBUTES[0],\n",
    ") -> pd.DataFrame:\n",
    "    pd_data = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    pd_data = pd_data.sort_values(by=sort_by_column_name, ascending=True)\n",
    "    pd_data = pd_data.reset_index(drop=True)\n",
    "    return pd_data\n",
    "\n",
    "\n",
    "def write_pd_to_csv(data:pd.DataFrame, file: str,\n",
    "                    sort_by_column_name: Optional[str] = RAW_ATTRIBUTES[0]) -> None:\n",
    "    data = data.reset_index(drop=True)\n",
    "    data = data.sort_values(by=sort_by_column_name, ascending=True)\n",
    "    data.to_csv(file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "def write_to_csv_formatted(\n",
    "    data: Union[pd.DataFrame, TimeSeries], file: str, sort_by_column_name: Optional[str] = RAW_ATTRIBUTES[0]\n",
    ") -> None:\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        _raise_error_if_nan_value(data)\n",
    "        write_pd_to_csv(data,file,sort_by_column_name)\n",
    "    elif isinstance(data, TimeSeries):\n",
    "        if not data.has_range_index:\n",
    "            raise ValueError(f\"Index for the time series is not a range index\")\n",
    "        _raise_error_if_nan_value(data.pd_dataframe())\n",
    "        data.pd_dataframe().to_csv(file, index=True,encoding=\"utf-8\")\n",
    "    else:\n",
    "        raise TypeError(\"data must be a DataFrame or a TimeSeries\")\n",
    "\n",
    "\n",
    "def _raise_error_if_nan_value(data: pd.DataFrame) -> None:\n",
    "    if data.empty:\n",
    "        raise ValueError(\n",
    "            \"DataFrame contains empty values at row(s): \"\n",
    "            + str(list(data.index))\n",
    "        )\n",
    "\n",
    "    if data.isna().sum().sum() > 0:\n",
    "        na_rows = data.index[data.isna().any(axis=1)].tolist()\n",
    "        raise ValueError(\n",
    "            \"DataFrame contains NaN values at row(s): \" + str(na_rows)\n",
    "        )\n",
    "\n",
    "    if (data == \".\").sum().sum() > 0:\n",
    "        dot_rows = data.index[(data == \".\").any(axis=1)].tolist()\n",
    "        raise ValueError(\n",
    "            'DataFrame contains values that are exactly equal to \".\" at row(s): '\n",
    "            + str(dot_rows)\n",
    "        )\n",
    "\n",
    "def clear_directory_content(directory_path : str, exclusions : Optional[int] = None) -> None:\n",
    "    if exclusions is None:\n",
    "        exclusions = []\n",
    "    if os.path.exists(directory_path):\n",
    "        for filename in os.listdir(directory_path):\n",
    "            if filename in exclusions:\n",
    "                continue\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
