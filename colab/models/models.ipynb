{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa98acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers.tensorboard import TensorBoardLogger\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "from pytorch_forecasting import TimeSeriesDataSet, BaseModelWithCovariates\n",
    "from pytorch_forecasting.data import GroupNormalizer, MultiNormalizer\n",
    "from typing import Callable, Union, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "import threading\n",
    "from mean_reversion.models.model_customizer import CustomNHiTS,CustomDeepAR,CustomTemporalFusionTransformer,CustomlRecurrentNetwork\n",
    "from mean_reversion.config.config_utils import ConfigManager, ModelValueRetriver\n",
    "from mean_reversion.utils import clear_directory_content, read_json, save_json\n",
    "from mean_reversion.models.common import get_risk_rewards_metrics\n",
    "from mean_reversion.config.constants import DATASETS\n",
    "import pytz\n",
    "import datetime\n",
    "import re\n",
    "import subprocess\n",
    "import glob\n",
    "import copy\n",
    "import optuna\n",
    "import pickle\n",
    "from abc import ABC, abstractmethod\n",
    "import logging\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63025ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL = {\n",
    "    \"NHiTS\": CustomNHiTS,\n",
    "    \"DeepAR\": CustomDeepAR,\n",
    "    \"TemporalFusionTransformer\": CustomTemporalFusionTransformer,\n",
    "    \"RecurrentNetwork\": CustomlRecurrentNetwork\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832e2645",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModelBuilder(ABC):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_manager: ConfigManager = ConfigManager(),\n",
    "        values_retriver = ModelValueRetriver()\n",
    "    ):\n",
    "        self._config_manager = config_manager\n",
    "        self._config = self._config_manager.config\n",
    "        self._params = {}\n",
    "        self._datasets = DATASETS\n",
    "        self._model_dir = ''\n",
    "        self._lightning_logs_dir = ''\n",
    "        self._logger = None\n",
    "        self._model_name = ''\n",
    "        self._values_retriever = values_retriver\n",
    "        self._extra_dirpath = ''\n",
    "        self._lower_index = ''\n",
    "        self._upper_index = ''\n",
    "        self._best_model : Optional[BaseModelWithCovariates] = ''\n",
    "\n",
    "\n",
    "    def _assign_params(self, hyperparameters_phase : Optional[str] = 'hyperparameters'):\n",
    "        params = {}\n",
    "        model_config = read_json(\n",
    "            \"resources/configs/models_args.json\"\n",
    "        )[\"common\"]\n",
    "        for item in model_config.keys():\n",
    "            if item in self._config[hyperparameters_phase][\"common\"]:\n",
    "                params[item] = self._config[hyperparameters_phase][\"common\"][item]\n",
    "            else :\n",
    "                params[item] = None\n",
    "        return params\n",
    "\n",
    "    def _clean_directory(self, exclusions : Optional[list] = None):\n",
    "        clear_directory_content(self._model_dir, exclusions)\n",
    "        os.makedirs(self._model_dir, exist_ok=True)\n",
    "        self._cleanup_logs(self._lightning_logs_dir)\n",
    "        self._cleanup_logs(f'{self._lightning_logs_dir}/{self._model_name}')\n",
    "\n",
    "    @staticmethod\n",
    "    def _cleanup_logs(base_dir, keep=5):\n",
    "        if not os.path.exists(base_dir):\n",
    "            return\n",
    "        versions = [d for d in Path(base_dir).iterdir() if\n",
    "                    d.is_dir() and 'version_' in d.name]\n",
    "        sorted_versions = sorted(versions, key=os.path.getctime, reverse=True)\n",
    "        for version in sorted_versions[keep:]:\n",
    "            shutil.rmtree(version)\n",
    "\n",
    "    def _obtain_data(self):\n",
    "\n",
    "        if self._config[\"inputs\"][\"future_covariates\"]['data']:\n",
    "            self._categorical_cols = \\\n",
    "                self._config[\"inputs\"][\"future_covariates\"]['data']\n",
    "\n",
    "            for dataset in self._datasets:\n",
    "                input_future = pd.read_csv(\n",
    "                    self._config[\"inputs\"][\"future_covariates\"][\"common\"][\n",
    "                        \"model_data\"][dataset])\n",
    "                for category in self._categorical_cols :\n",
    "                    input_future[category] = input_future[category].astype(str)\n",
    "                setattr(self, f'_input_future_{dataset}', input_future)\n",
    "        else:\n",
    "            self._categorical_cols = []\n",
    "\n",
    "        for dataset in self._datasets:\n",
    "            input_past = pd.read_csv(\n",
    "                f\"resources/input/model_data/input_past_{dataset}.csv\")\n",
    "            input_past.columns = input_past.columns.str.replace('.', '_',\n",
    "                                                                regex=True)\n",
    "            setattr(self, f'_input_past_{dataset}', input_past)\n",
    "\n",
    "            output = pd.read_csv(f\"resources/input/model_data/output_{dataset}.csv\")\n",
    "            setattr(self, f'_output_{dataset}', output)\n",
    "\n",
    "    def _assign_data_models(self):\n",
    "        for dataset_type in self._datasets:\n",
    "            input_past = getattr(self, f'_input_past_{dataset_type}')\n",
    "            input_future = getattr(self, f'_input_future_{dataset_type}',\n",
    "                                   pd.DataFrame())\n",
    "            output = getattr(self, f'_output_{dataset_type}')\n",
    "\n",
    "            if not input_future.empty:\n",
    "                input_future = input_future.drop(columns=['time'])\n",
    "            output = output.drop(columns=['time'])\n",
    "\n",
    "            data = pd.concat([input_past, input_future, output], axis=1)\n",
    "            data['group'] = 'group_1'\n",
    "            setattr(self, f'_{dataset_type}_data', data)\n",
    "\n",
    "    def _obtain_dataloader(self):\n",
    "\n",
    "        self._continuous_cols = [col for col in self._input_past_train.columns if col not in [\"time\"]]\n",
    "        self._targets = [col for col in self._output_train.columns if col not in [\"time\"]]\n",
    "        if len(self._targets) > 1 :\n",
    "            list_of_normalizers = []\n",
    "            for target in self._targets:\n",
    "                list_of_normalizers.append(GroupNormalizer(\n",
    "                groups=[\"group\"]\n",
    "            ))\n",
    "            target_normalizer = MultiNormalizer(list_of_normalizers)\n",
    "        else :\n",
    "            target_normalizer = GroupNormalizer(\n",
    "                groups=[\"group\"]\n",
    "            )\n",
    "\n",
    "        self._continuous_cols.extend(self._targets)\n",
    "        self._add_encoder_length = True\n",
    "        self._add_relative_time_idx = True\n",
    "        self._add_target_scales = True\n",
    "        self._static_categoricals = [\"group\"]\n",
    "\n",
    "        if \"NHiTS\" in self._model_name :\n",
    "            self._categorical_cols = []\n",
    "            self._add_relative_time_idx = False\n",
    "            self._add_encoder_length = False\n",
    "            self._add_target_scales = False\n",
    "            self._static_categoricals = []\n",
    "\n",
    "        self._training_dataset = TimeSeriesDataSet(\n",
    "            self._train_data,\n",
    "            time_idx=\"time\",\n",
    "            target=self._targets,\n",
    "            group_ids=[\"group\"],\n",
    "            static_categoricals=self._static_categoricals,\n",
    "            max_encoder_length=self._params[\"max_encoder_length\"],\n",
    "            max_prediction_length=self._params[\"max_prediction_length\"],\n",
    "            time_varying_known_categoricals=self._categorical_cols,\n",
    "            time_varying_unknown_reals=self._continuous_cols,\n",
    "            add_encoder_length=self._add_encoder_length,\n",
    "            add_relative_time_idx= self._add_relative_time_idx,\n",
    "            add_target_scales=self._add_target_scales,\n",
    "            target_normalizer=target_normalizer\n",
    "        )\n",
    "\n",
    "\n",
    "        self._train_dataloader = self._training_dataset.to_dataloader(train=True, batch_size=self._params['batch_size'])\n",
    "        self._predict_dataset = TimeSeriesDataSet.from_dataset(self._training_dataset, self._predict_data, predict=False, stop_randomization=True)\n",
    "        self._predict_dataloader = self._predict_dataset.to_dataloader(train=False, batch_size=self._params['batch_size']*5000)\n",
    "        self._test_dataset = TimeSeriesDataSet.from_dataset(self._training_dataset, self._test_data, predict=False, stop_randomization=True)\n",
    "        self._test_dataloader = self._test_dataset.to_dataloader(train=False, batch_size=self._params['batch_size']*5000)\n",
    "\n",
    "    def _train_model(self, hyperparameters : dict, hyperparameter_phase: Optional[str] = 'hyperparameters'):\n",
    "        pl.seed_everything(self._params['random_state'])\n",
    "        model_to_train = CUSTOM_MODEL[self._model_name]\n",
    "\n",
    "        self._model = model_to_train.from_dataset(\n",
    "            dataset=self._training_dataset,\n",
    "            **hyperparameters[self._model_name],\n",
    "        )\n",
    "\n",
    "        callbacks_list = []\n",
    "        callbacks = self._config_manager.get_callbacks(self._model_name,hyperparameter_phase,self._extra_dirpath)['callbacks']\n",
    "        for callback in callbacks:\n",
    "            if isinstance(callback,\n",
    "                          ModelCheckpoint):\n",
    "                self._model_checkpoint = copy.deepcopy(callback)\n",
    "                callbacks_list.append(callback)\n",
    "            if isinstance(callback,\n",
    "                          EarlyStopping):\n",
    "                callbacks_list.append(copy.deepcopy(callback))\n",
    "\n",
    "        if not callbacks_list:\n",
    "            callbacks_list = None\n",
    "\n",
    "        if self._lightning_logs_dir:\n",
    "            self._logger = TensorBoardLogger(self._lightning_logs_dir,\n",
    "                                             name=self._model_name)\n",
    "        if torch.cuda.is_available():\n",
    "            accelerator = 'gpu'\n",
    "        else :\n",
    "            accelerator = 'auto'\n",
    "\n",
    "        self._trainer = pl.Trainer(\n",
    "            max_epochs=self._params[\"epochs\"],\n",
    "            callbacks=callbacks_list,\n",
    "            logger=self._logger,\n",
    "            gradient_clip_val=self._params[\"gradient_clip_val\"],\n",
    "            enable_model_summary=True,\n",
    "            accelerator= accelerator\n",
    "        )\n",
    "\n",
    "        self._trainer.fit(self._model,\n",
    "                          train_dataloaders=self._train_dataloader,\n",
    "                          val_dataloaders=self._predict_dataloader)\n",
    "\n",
    "    def _coordinate_metrics_calculation(self,\n",
    "                                        dataloader,\n",
    "                                        data,\n",
    "                                        dataset_type,\n",
    "                                        is_execute_all: Optional[bool] = True):\n",
    "        self._raw_predictions = self._best_model.predict(dataloader,\n",
    "                                                         mode=\"raw\",\n",
    "                                                         return_x=True,\n",
    "                                                         return_y=True)\n",
    "        self._initialize_metric_variables()\n",
    "        for target_item, prediction in enumerate(\n",
    "                self._raw_predictions.output.prediction):\n",
    "            self._target_item = target_item\n",
    "            self._preds_current_stock = prediction\n",
    "            self._gather_metrics(dataloader, data)\n",
    "            self._calculate_metrics(data)\n",
    "            if is_execute_all:\n",
    "                self._plot_predictions(dataset_type)\n",
    "\n",
    "        self._calculate_aggregate_metrics(dataset_type)\n",
    "        if is_execute_all:\n",
    "            self._save_metrics(dataset_type)\n",
    "\n",
    "\n",
    "    def _gather_metrics(self, dataloader, current_data_set):\n",
    "        self._current_all_preds = []\n",
    "        self._current_all_actuals = []\n",
    "        self._returns_on_trade_list = []\n",
    "        self._preds_class = []\n",
    "        self._actual_class = []\n",
    "        self._time_indices = []\n",
    "        self._cumulative_predicted_return = 1\n",
    "        self._cumulative_actual_return = 1\n",
    "        self._cumulative_index = len(current_data_set) - len(\n",
    "            dataloader.dataset)\n",
    "        max_drawdown = 0\n",
    "        peak = self._cumulative_predicted_return\n",
    "\n",
    "        for index in range(self._preds_current_stock.shape[0]):\n",
    "            current_prediction, indices = self._preds_current_stock[index][0].sort()\n",
    "            median_pred_value = current_prediction.median(dim=0).values\n",
    "            if current_prediction.shape[0] == 1:\n",
    "                lower_value = median_pred_value\n",
    "                upper_value = median_pred_value\n",
    "            else :\n",
    "                lower_value = current_prediction[self._lower_index]\n",
    "                upper_value = current_prediction[self._upper_index]\n",
    "\n",
    "            actual_value = self._raw_predictions.y[0][self._target_item][index].item()\n",
    "\n",
    "            if not self._config[\"common\"][\n",
    "                \"make_data_stationary\"] and index == 0:\n",
    "                continue\n",
    "\n",
    "            if not self._config[\"common\"][\"make_data_stationary\"]:\n",
    "                actual_return = (actual_value / self._raw_predictions.y[0][self._target_item][\n",
    "                    index - 1].item()) - 1\n",
    "                median_pred_return = (median_pred_value / self._raw_predictions.y[0][self._target_item][\n",
    "                    index - 1].item()) - 1\n",
    "                upper_return = (upper_value / self._raw_predictions.y[0][self._target_item][\n",
    "                    index - 1].item()) - 1\n",
    "                lower_return = (lower_value / self._raw_predictions.y[0][self._target_item][\n",
    "                    index - 1].item()) - 1\n",
    "\n",
    "            else:\n",
    "                median_pred_return = median_pred_value\n",
    "                lower_return = lower_value\n",
    "                upper_return = upper_value\n",
    "                actual_return = actual_value\n",
    "\n",
    "            if lower_return > 0 and upper_return > 0:\n",
    "                self._cumulative_predicted_return *= (\n",
    "                        1 + actual_return)\n",
    "                self._returns_on_trade_list.append(actual_return)\n",
    "                self._preds_class.append(median_pred_return)\n",
    "                self._actual_class.append(actual_return)\n",
    "\n",
    "            elif upper_return < 0 and lower_return < 0:\n",
    "                self._cumulative_predicted_return *= (1 - actual_return)\n",
    "                self._returns_on_trade_list.append(-actual_return)\n",
    "                self._preds_class.append(median_pred_return)\n",
    "                self._actual_class.append(actual_return)\n",
    "\n",
    "            if self._cumulative_predicted_return > peak:\n",
    "                peak = self._cumulative_predicted_return\n",
    "            else:\n",
    "                drawdown = (peak - self._cumulative_predicted_return) / peak\n",
    "                if drawdown > max_drawdown:\n",
    "                    max_drawdown = drawdown\n",
    "\n",
    "            self._cumulative_actual_return *= (1 + actual_return)\n",
    "            self._time_indices.append(current_data_set[\"time\"].iloc[self._cumulative_index])\n",
    "            self._cumulative_index += 1\n",
    "            self._current_all_preds.append(median_pred_return)\n",
    "            self._current_all_actuals.append(actual_return)\n",
    "\n",
    "        self._current_all_preds = [prediction.item() for prediction in\n",
    "                                       self._current_all_preds]\n",
    "        self._max_drawdown = max_drawdown\n",
    "        self._returns_on_trade = torch.tensor(self._returns_on_trade_list)\n",
    "\n",
    "    def _initialize_metric_variables(self):\n",
    "        self._actual_return_on_risk = []\n",
    "        self._naive_forecast_rmse = []\n",
    "        self._f1_score_value = []\n",
    "        self._rmse = []\n",
    "        self._nb_trades =[]\n",
    "        self._all_preds_returns = []\n",
    "        self._all_actual_returns = []\n",
    "        self._max_drawdown_all = []\n",
    "        self._return_on_risk = []\n",
    "        self._returns_on_trade_all = []\n",
    "\n",
    "\n",
    "    def _calculate_metrics(self,\n",
    "                         forecast_data):\n",
    "\n",
    "        predicted_return_class = [1 if ret >= 0 else 0 for ret in\n",
    "                                  self._preds_class]\n",
    "        actual_return_class = [1 if ret >= 0 else 0 for ret in self._actual_class]\n",
    "        self._f1_score_value.append(f1_score(actual_return_class, predicted_return_class,\n",
    "                                  average='weighted'))\n",
    "        self._all_actual_returns.append(self._cumulative_actual_return)\n",
    "        self._max_drawdown_all.append(self._max_drawdown)\n",
    "        self._all_preds_returns.append(self._cumulative_predicted_return)\n",
    "        self._rmse.append(np.sqrt(\n",
    "            mean_squared_error(self._current_all_actuals, self._current_all_preds)))\n",
    "        if self._params[\"max_encoder_length\"] <= 20:\n",
    "            rolling_windows = self._params[\"max_encoder_length\"] - 1\n",
    "        else :\n",
    "            rolling_windows = 20\n",
    "        naive_forecast = forecast_data[self._targets[self._target_item]].rolling(rolling_windows).mean()\n",
    "        naive_forecast = naive_forecast[len(forecast_data) - len(self._current_all_actuals):].values\n",
    "\n",
    "        self._naive_forecast_rmse.append(np.sqrt(\n",
    "            mean_squared_error(self._current_all_actuals, naive_forecast)))\n",
    "        risk_reward_metrics = get_risk_rewards_metrics(self._returns_on_trade)\n",
    "        self._return_on_risk.append(risk_reward_metrics['return_on_risk'])\n",
    "        self._returns_on_trade_all.append(risk_reward_metrics['annualized_risk'])\n",
    "        self._nb_trades.append(len(self._returns_on_trade_list))\n",
    "\n",
    "        actual_annualized_return = \\\n",
    "            (self._cumulative_actual_return)** (252 / len(self._current_all_actuals)) - 1\n",
    "        actual_daily_returns = np.array(self._current_all_actuals)\n",
    "        actual_annualized_risk = np.std(actual_daily_returns) * (252 ** 0.5)\n",
    "        self._actual_return_on_risk.append(actual_annualized_return / actual_annualized_risk if actual_annualized_risk != 0 else 0)\n",
    "\n",
    "    def _obtain_aggregate_metrics(self, metrics_to_obtain_average):\n",
    "        weighted_av_metrics = []\n",
    "        for metric in metrics_to_obtain_average:\n",
    "            if sum(self._nb_trades) == 0:\n",
    "                if isinstance(metric, torch.Tensor):\n",
    "                    weighted_av_metrics.append(torch.tensor(0))\n",
    "                else:\n",
    "                    weighted_av_metrics.append(0)\n",
    "            else :\n",
    "                weighted_av_metrics.append(\n",
    "                    sum([a * b for a, b in zip(metric, self._nb_trades)]) / sum(\n",
    "                        self._nb_trades))\n",
    "        return weighted_av_metrics\n",
    "\n",
    "    def _calculate_aggregate_metrics(self, dataset_type):\n",
    "        if not hasattr(self, '_metrics'):\n",
    "            self._metrics = {}\n",
    "\n",
    "        weighted_av_metrics = self._obtain_aggregate_metrics(\n",
    "            [self._rmse, self._f1_score_value, self._naive_forecast_rmse,\n",
    "             self._return_on_risk, self._actual_return_on_risk, self._returns_on_trade_all]\n",
    "        )\n",
    "        self._aggregated_return_on_risk = weighted_av_metrics[3]\n",
    "\n",
    "        self._metrics[dataset_type] = {\n",
    "            \"rmse\": weighted_av_metrics[0],\n",
    "            \"f1_score\": weighted_av_metrics[1],\n",
    "            \"naive_forecast_rmse\": weighted_av_metrics[2],\n",
    "            \"rmse_vs_naive\": weighted_av_metrics[0] / weighted_av_metrics[2] if weighted_av_metrics[2]!=0 else 0,\n",
    "            \"return\": weighted_av_metrics[5].item(),\n",
    "            \"actual_return\": np.prod(self._all_actual_returns) - 1,\n",
    "            \"return_on_risk\": weighted_av_metrics[3].item(),\n",
    "            \"actual_return_on_risk\": weighted_av_metrics[4],\n",
    "            \"max_drawdown\": self._max_drawdown_all,\n",
    "            \"nb_of_trades\": sum(self._nb_trades)\n",
    "        }\n",
    "\n",
    "    def _save_metrics(self, dataset_type):\n",
    "        metrics_path = os.path.join(\n",
    "            f'{self._model_dir}', 'metrics.json')\n",
    "        if os.path.exists(metrics_path):\n",
    "            with open(metrics_path, 'r', encoding='utf-8') as f:\n",
    "                existing_metrics = json.load(f)\n",
    "            existing_metrics[dataset_type] = self._metrics[dataset_type]\n",
    "        else:\n",
    "            existing_metrics = {dataset_type: self._metrics[dataset_type]}\n",
    "\n",
    "        with open(metrics_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(existing_metrics, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    def _plot_predictions(self, dataset_type):\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self._time_indices, self._current_all_preds, color='blue',\n",
    "                 label='Predicted Values')\n",
    "        plt.plot(self._time_indices, self._current_all_actuals, color='black',\n",
    "                 label='Actual Values')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Output')\n",
    "        plt.title(f'Actual vs Predicted Values over time - {dataset_type}')\n",
    "        plt.legend()\n",
    "        asset = self._targets[self._target_item].replace(\"_target\",'')\n",
    "        plt.savefig(os.path.join(f'{self._model_dir}',\n",
    "                                 f'{asset}_forecast_{dataset_type}.png'))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b09129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuilder(BaseModelBuilder):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_manager: ConfigManager,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._config_manager = config_manager\n",
    "        self._config = self._config_manager.config\n",
    "        self._params = self._assign_params()\n",
    "\n",
    "        self._lightning_logs_dir = 'lightning_logs'\n",
    "        self._lower_index, self._upper_index = self._values_retriever.confidence_indexes\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        for model in self._config[\"hyperparameters\"][\"models\"]:\n",
    "            self._obtain_data()\n",
    "            self._model_name = model\n",
    "            self._assign_data_models()\n",
    "            self._obtain_dataloader()\n",
    "            self._model_dir = f'models/{self._model_name}'\n",
    "            self._clean_directory()\n",
    "            self._train_model(self._config_manager.hyperparameters)\n",
    "            self._obtain_best_model()\n",
    "            self._coordinate_evaluation()\n",
    "            self._save_metrics_from_tensorboardflow()\n",
    "            self._coordinate_interpretions()\n",
    "            self._save_run_information()\n",
    "            self._coordinate_select_best_model()\n",
    "\n",
    "\n",
    "\n",
    "    def _obtain_best_model(self):\n",
    "        best_model_path = self._model_checkpoint.best_model_path\n",
    "        self._best_model = self._model.load_from_checkpoint(best_model_path)\n",
    "        #self._best_model = self._model.load_from_checkpoint('tempo/TemporalFusionTransformer/best_model.ckpt')\n",
    "\n",
    "\n",
    "    def _coordinate_interpretions(self):\n",
    "        if \"TemporalFusionTransformer\" in self._model_name:\n",
    "            self._interpret_features_importance()\n",
    "        self._interpret_features_sensitivity()\n",
    "\n",
    "\n",
    "    def _interpret_features_sensitivity(self):\n",
    "\n",
    "        raw_predictions = self._best_model.predict(self._predict_dataloader,\n",
    "                                           return_x=True)\n",
    "        predictions_vs_actuals = self._best_model.calculate_prediction_actual_by_variable(\n",
    "            raw_predictions.x, raw_predictions.output)\n",
    "        features_sensitivity_path = f'{self._model_dir}/features_sensitivity'\n",
    "        os.makedirs(features_sensitivity_path, exist_ok=True)\n",
    "        try :\n",
    "            self._save_multiple_interprations_plot(predictions_vs_actuals,\n",
    "                                                   features_sensitivity_path,\n",
    "                                                   self._best_model.plot_prediction_actual_by_variable)\n",
    "        except :\n",
    "            pass\n",
    "\n",
    "    def _interpret_features_importance(self):\n",
    "        raw_predictions = self._best_model.predict(self._predict_dataloader,\n",
    "                                                   mode=\"raw\",\n",
    "                                                   return_x=True)\n",
    "\n",
    "        interpretations = self._best_model.interpret_output(\n",
    "            raw_predictions.output,\n",
    "            reduction=\"sum\"\n",
    "        )\n",
    "\n",
    "        features_importance_dir = f'{self._model_dir }/features_importance'\n",
    "        os.makedirs(features_importance_dir, exist_ok=True)\n",
    "        self._save_multiple_interprations_plot(interpretations,\n",
    "                                               features_importance_dir,\n",
    "                                               self._best_model.plot_interpretation)\n",
    "\n",
    "    def _save_multiple_interprations_plot(self, interpretations,\n",
    "                                          directory_to_save,\n",
    "                                          plot_function: Callable) -> None:\n",
    "        original_backend = plt.get_backend()\n",
    "        plt.switch_backend(\"Agg\")\n",
    "        plot_function(interpretations)\n",
    "        for i, fig_num in enumerate(plt.get_fignums()):\n",
    "            fig = plt.figure(fig_num)\n",
    "\n",
    "            for j, ax in enumerate(fig.get_axes()):\n",
    "                title = ax.get_title()\n",
    "                interpretation_file_path = os.path.join(directory_to_save,f'{title}.png')\n",
    "                fig.savefig(interpretation_file_path)\n",
    "                break\n",
    "\n",
    "            plt.close(fig)\n",
    "\n",
    "        plt.switch_backend(original_backend)\n",
    "\n",
    "\n",
    "    def _coordinate_select_best_model(self):\n",
    "        self._is_new_model_better = True\n",
    "        self._best_metrics = {}\n",
    "        self._current_metrics = {}\n",
    "        for dataloader, data, dataset_type in [(self._predict_dataloader, self._predict_data, 'predict'), (self._test_dataloader, self._test_data, 'test')]:\n",
    "            if dataloader is None or data is None:\n",
    "                continue\n",
    "            self._dataset_type = dataset_type\n",
    "            self._select_best_model()\n",
    "        if self._is_new_model_better:\n",
    "            self._save_best_model()\n",
    "\n",
    "\n",
    "    def _select_best_model(self) -> None:\n",
    "        best_model_metrics_file = self._obtain_best_metrics_path()\n",
    "        if best_model_metrics_file:\n",
    "            self._best_metrics[self._dataset_type]= read_json(best_model_metrics_file)[self._dataset_type]\n",
    "            self._current_metrics[self._dataset_type] = self._filter_relevant_metrics()\n",
    "            if self._is_new_model_better:\n",
    "                is_model_better_func = getattr(self, f\"_is_model_better_{self._dataset_type}\")\n",
    "                self._is_new_model_better = is_model_better_func()\n",
    "        else:\n",
    "            self._save_best_model()\n",
    "\n",
    "    def _obtain_best_metrics_path(self):\n",
    "        most_recent_directory = self._obtain_most_recent_directory()\n",
    "        if most_recent_directory:\n",
    "            for root, _, files in os.walk(most_recent_directory):\n",
    "                if \"metrics.json\" in files:\n",
    "                    return os.path.join(root, \"metrics.json\")\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    def _obtain_most_recent_directory(self) -> Union[str,None]:\n",
    "        pattern = re.compile(\"^\\d{8}$\")\n",
    "        directories = [\n",
    "            d\n",
    "            for d in os.listdir(self._config[\"common\"][\"best_model_path\"])\n",
    "            if os.path.isdir(os.path.join(self._config[\"common\"][\"best_model_path\"], d))\n",
    "        ]\n",
    "        if directories :\n",
    "            date_directories = [d for d in directories if pattern.match(d)]\n",
    "\n",
    "            date_directories.sort(reverse=True)\n",
    "            most_recent_directory = date_directories[0]\n",
    "\n",
    "            return os.path.join(self._config[\"common\"][\"best_model_path\"], most_recent_directory)\n",
    "        return None\n",
    "\n",
    "    def _save_best_model(self) -> None:\n",
    "\n",
    "        best_model_dir = os.path.join(\n",
    "            self._config[\"common\"][\"best_model_path\"],\n",
    "            datetime.datetime.now().strftime(\"%Y%m%d\"),\n",
    "            self._model_name\n",
    "        )\n",
    "\n",
    "        best_root_dir = os.path.join(\n",
    "            self._config[\"common\"][\"best_model_path\"],\n",
    "            datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "        )\n",
    "        if os.path.exists(best_root_dir):\n",
    "            shutil.rmtree(best_root_dir)\n",
    "        shutil.copytree(self._model_dir, best_model_dir)\n",
    "        shutil.copy(\"config.yaml\", best_root_dir)\n",
    "\n",
    "        ckpt_files = glob.glob(os.path.join(best_model_dir, '*.ckpt'))\n",
    "        for file in ckpt_files:\n",
    "            os.remove(file)\n",
    "\n",
    "        subprocess.run(['git', 'add',best_root_dir])\n",
    "\n",
    "\n",
    "    def _is_model_better_predict(\n",
    "        self) -> bool:\n",
    "        for metric in self._current_metrics[self._dataset_type]:\n",
    "            better_func = getattr(self, f\"_is_{metric}_performance_better\")\n",
    "            if metric not in self._best_metrics[self._dataset_type]:\n",
    "                return True\n",
    "            if not better_func(self._current_metrics[self._dataset_type][metric], self._best_metrics[self._dataset_type][metric]):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def _is_model_better_test(self) -> bool:\n",
    "        if 'return_on_risk' in self._current_metrics[self._dataset_type]:\n",
    "            if self._current_metrics['test']['return_on_risk'] \\\n",
    "                    < (self._config['common']['test_performance'] * self._current_metrics['predict']['return_on_risk']):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def _is_return_performance_better(\n",
    "        self, current: float, best: float\n",
    "    ) -> bool:\n",
    "        return current > best\n",
    "\n",
    "    def _is_return_on_risk_performance_better(self, current: float, best: float) -> bool:\n",
    "        return current > best\n",
    "\n",
    "\n",
    "    def _filter_relevant_metrics(self) :\n",
    "        metrics_to_choose_model = self._config[\"common\"][\n",
    "            \"metrics_to_choose_model\"\n",
    "        ]\n",
    "        return {\n",
    "            metric: self._metrics[self._dataset_type][metric] for metric in metrics_to_choose_model\n",
    "        }\n",
    "\n",
    "    def _coordinate_evaluation(self):\n",
    "\n",
    "        for dataloader, data, dataset_type in [(self._predict_dataloader, self._predict_data, 'predict'), (self._test_dataloader, self._test_data, 'test')]:\n",
    "            if dataloader is None or data is None:\n",
    "                continue\n",
    "\n",
    "            self._coordinate_metrics_calculation(dataloader,data,dataset_type)\n",
    "\n",
    "    def _save_metrics_from_tensorboardflow(self):\n",
    "        metrics_dict = {}\n",
    "\n",
    "        os.makedirs(f'{self._model_dir}/tensorboard', exist_ok=True)\n",
    "        for event_file in os.listdir(self._logger.log_dir):\n",
    "            if not event_file.startswith('events.out.tfevents'):\n",
    "                continue\n",
    "            full_path = os.path.join(self._logger.log_dir, event_file)\n",
    "            ea = event_accumulator.EventAccumulator(full_path)\n",
    "            ea.Reload()\n",
    "\n",
    "            for tag in ea.Tags()['scalars']:\n",
    "                metrics_dict[tag] = ea.Scalars(tag)\n",
    "\n",
    "        for metric, scalars in metrics_dict.items():\n",
    "            plt.figure(figsize=(10, 5))\n",
    "\n",
    "            if metric == 'train_loss_step':\n",
    "                steps = [scalar.step for scalar in scalars]\n",
    "            else:\n",
    "                steps = list(range(len(scalars)))\n",
    "\n",
    "            values = [scalar.value for scalar in scalars]\n",
    "            plt.plot(steps, values, label=metric)\n",
    "            plt.xlabel('Steps' if metric == 'train_loss_step' else 'Epoch')\n",
    "            plt.ylabel('Value')\n",
    "            plt.title(metric)\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.savefig(f\"{self._model_dir}/tensorboard/{metric.replace('/', '_')}.png\")\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "    def _save_run_information(self) -> None:\n",
    "        data = {}\n",
    "        est = pytz.timezone('US/Eastern')\n",
    "        now_in_est = datetime.datetime.now(est)\n",
    "        date_str = now_in_est.strftime(\"%Y-%m-%d %H:%M\")\n",
    "        data['last_run_time'] = date_str\n",
    "        data['last_epoch_trained'] = self._trainer.current_epoch + 1\n",
    "        save_json(\n",
    "            os.path.join(\n",
    "                self._model_dir,\n",
    "                \"run_information.json\"\n",
    "            ),\n",
    "            data,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c767a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperpametersOptimizer(BaseModelBuilder):\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_manager: ConfigManager\n",
    "\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._config_manager = config_manager\n",
    "        self._config = config_manager.config\n",
    "        #self._lightning_logs_dir = 'lightning_logs/model_optimization'\n",
    "        self._params_to_optimized = self._assign_params(hyperparameters_phase='hyperparameters_optimization')\n",
    "\n",
    "        self._model_suggested_type = {}\n",
    "        self._current_trial = 0\n",
    "        self._extra_dirpath = 'trial_v' + str(self._current_trial)\n",
    "\n",
    "    def run(self):\n",
    "        n_trials = self._config['common']['hyperparameters_optimization'][\n",
    "            'nb_trials']\n",
    "\n",
    "\n",
    "        self._current_hyperparameters = {}\n",
    "        for model in self._config[\"hyperparameters_optimization\"][\"models\"]:\n",
    "            self._current_hyperparameters['model'] = {}\n",
    "            self._model_suggested_type = \\\n",
    "                self._config_manager.get_model_suggest_type(model)\n",
    "            self._model_name = model\n",
    "            optuna_storage = 'last_study.db'\n",
    "            self._model_dir = f'models/hyperparameters_optimization/{self._model_name}'\n",
    "            self._clean_directory(exclusions=[optuna_storage])\n",
    "            if self._config['common']['hyperparameters_optimization'][\n",
    "                'is_pruning']:\n",
    "\n",
    "                pruner = optuna.pruners.MedianPruner(n_startup_trials=5,\n",
    "                                                     n_warmup_steps=5,\n",
    "                                                     interval_steps=5)\n",
    "\n",
    "            else:\n",
    "                pruner = None\n",
    "            sampler = optuna.samplers.TPESampler()\n",
    "            storage_name = f\"sqlite:///{os.path.join(self._model_dir, optuna_storage)}\"\n",
    "            if os.path.exists(os.path.join(self._model_dir, optuna_storage)):\n",
    "                    os.remove(os.path.join(self._model_dir, optuna_storage))\n",
    "\n",
    "            try :\n",
    "                study = optuna.load_study(pruner = pruner,\n",
    "                                            study_name= optuna_storage.replace('.db',''),\n",
    "                                            storage= storage_name,\n",
    "                                            sampler=sampler)\n",
    "                n_trials -= len(study.trials)\n",
    "\n",
    "            except KeyError as key_error:\n",
    "                logging.warning(f\"Study name doesn't exists: {key_error}\")\n",
    "\n",
    "                study = optuna.create_study(direction='maximize',\n",
    "                                            pruner = pruner,\n",
    "                                            study_name= optuna_storage.replace('.db',''),\n",
    "                                            storage= storage_name,\n",
    "                                            sampler=sampler,\n",
    "                                            load_if_exists=True)\n",
    "\n",
    "            study.optimize(self._objective, n_trials=n_trials,show_progress_bar=True)\n",
    "\n",
    "            with open(f\"{self._model_dir}/best_study.pkl\", \"wb\") as fout:\n",
    "                pickle.dump(study, fout)\n",
    "            print(study.best_params)\n",
    "            self._values_retriever.confidence_indexes = ''\n",
    "\n",
    "\n",
    "    def _objective(self, trial: optuna.Trial):\n",
    "        self._obtain_data()\n",
    "        self._assign_data_models()\n",
    "        self._hyper_possible_values = self._config_manager.hyperparameters_to_optimize[self._model_name]\n",
    "        self._current_suggested_type = self._model_suggested_type\n",
    "        self._current_hyperparameters[self._model_name] = self._assign_hyperparameters(trial)\n",
    "\n",
    "        self._hyper_possible_values = self._params_to_optimized\n",
    "        self._current_suggested_type = {**self._model_suggested_type,**self._config_manager.get_model_suggest_type('common', model_argument_type='')}\n",
    "        self._params = self._assign_hyperparameters(trial)\n",
    "\n",
    "        self._adjust_hyperparameters()\n",
    "        self._obtain_dataloader()\n",
    "        self._train_model(self._current_hyperparameters,hyperparameter_phase='hyperparameters_optimization')\n",
    "        if 'likelihood' in self._params:\n",
    "            self._params['likelihood'] =  self._config['hyperparameters_optimization'][\"common\"]['likelihood']\n",
    "        if self._model.current_epoch == 0:\n",
    "            music_thread = threading.Thread(\n",
    "                target=os.system('afplay super-mario-bros.mp3'))\n",
    "            music_thread.start()\n",
    "            raise ValueError(\n",
    "                f'Model only trained for {self._model.current_epoch} epoch. Training terminated prematurely.')\n",
    "\n",
    "        checkpoint = torch.load(\n",
    "            f\"{self._model_dir}/{self._extra_dirpath}/best_model.ckpt\")\n",
    "\n",
    "        model_checkpoint_key = next(\n",
    "            key for key in checkpoint[\"callbacks\"] if \"ModelCheckpoint\" in key)\n",
    "\n",
    "        best_value = checkpoint[\"callbacks\"][model_checkpoint_key][\n",
    "            'best_model_score'].item()\n",
    "\n",
    "        print(f'current best return on risk : {best_value}')\n",
    "\n",
    "        if best_value<=0:\n",
    "            self._reset_objective()\n",
    "            return best_value\n",
    "\n",
    "        self._best_model = self._model.load_from_checkpoint(\n",
    "            f\"{self._model_dir}/{self._extra_dirpath}/best_model.ckpt\")\n",
    "\n",
    "        self._coordinate_metrics_calculation(self._test_dataloader,self._test_data, 'test',False)\n",
    "\n",
    "        self._reset_objective()\n",
    "\n",
    "        print(f'Current test return on risk {self._aggregated_return_on_risk}')\n",
    "        if best_value * self._config['common']['test_performance'] > self._aggregated_return_on_risk:\n",
    "            return 0\n",
    "        print(f'\\nNb of trades on test set {sum(self._nb_trades)}')\n",
    "        if sum(self._nb_trades) <= self._config['common']['min_nb_trades']:\n",
    "            print(f'\\nLow nb of trades on test set {sum(self._nb_trades)}')\n",
    "            return 0\n",
    "\n",
    "        return best_value\n",
    "\n",
    "    def _reset_objective(self) :\n",
    "        shutil.rmtree(f\"{self._model_dir}/{self._extra_dirpath}\")\n",
    "        self._current_trial += 1\n",
    "        self._extra_dirpath = 'trial_v' + str(self._current_trial)\n",
    "\n",
    "    @staticmethod\n",
    "    def _find_closest_value(lst, K, exclude):\n",
    "        return min((abs(val - K), val) for val in lst if val not in exclude)[1]\n",
    "\n",
    "\n",
    "    def _adjust_hyperparameters(self):\n",
    "        if 'likelihood' in self._params and 'confidence_level' in self._params and\\\n",
    "                self._params['confidence_level'] != 0.5 and (self._params['confidence_level']\n",
    "                not in self._params['likelihood'] or (1-self._params['confidence_level'])\n",
    "                not in self._params['likelihood']):\n",
    "            to_remove_1 = self._find_closest_value(self._params['likelihood'], self._params['confidence_level'],\n",
    "                                  exclude=[0.5])\n",
    "            self._params['likelihood'].remove(to_remove_1)\n",
    "\n",
    "            to_remove_2 = self._find_closest_value(self._params['likelihood'], 1 - self._params['confidence_level'],\n",
    "                                  exclude=[0.5])\n",
    "            self._params['likelihood'].remove(to_remove_2)\n",
    "            self._params['likelihood'].append(self._params['confidence_level'])\n",
    "            self._params['likelihood'].append(1 - self._params['confidence_level'])\n",
    "\n",
    "        self._params['likelihood'].sort()\n",
    "\n",
    "        self._current_hyperparameters[self._model_name]['loss'] = ConfigManager.assign_loss_fct(self._current_hyperparameters[self._model_name],self._params)['loss']\n",
    "        self._upper_index = self._params['likelihood'].index(self._params['confidence_level'])\n",
    "        self._lower_index = self._params['likelihood'].index(1 - self._params['confidence_level'])\n",
    "        self._values_retriever.confidence_indexes = (self._lower_index,self._upper_index)\n",
    "\n",
    "    def _assign_hyperparameters(self, trial: optuna.Trial) -> dict:\n",
    "        hyperparameters_value = {}\n",
    "        for hyperparameter, hyper_properties in self._current_suggested_type.items():\n",
    "            current_value = self._process_hyperparameter(hyperparameter, hyper_properties,\n",
    "                                         trial)\n",
    "            if current_value:\n",
    "                hyperparameters_value[hyperparameter] = current_value\n",
    "        return hyperparameters_value\n",
    "\n",
    "    def _process_hyperparameter(self, hyperparameter, hyper_properties, trial):\n",
    "        suggest_methods = {\n",
    "            'suggest_categorical': lambda hyper, trial,\n",
    "                                          hyper_values: trial.suggest_categorical(\n",
    "                hyper, hyper_values),\n",
    "            'suggest_int': lambda hyper, trial, hyper_values: trial.suggest_int(\n",
    "                hyper, min(hyper_values), max(hyper_values)),\n",
    "            'suggest_float': lambda hyper, trial,\n",
    "                                    hyper_values: trial.suggest_float(\n",
    "                hyper, min(hyper_values), max(hyper_values)),\n",
    "        }\n",
    "\n",
    "\n",
    "        hyper_values = self._get_hyperparameter_value(hyperparameter)\n",
    "\n",
    "        if not hyper_values:\n",
    "            return None\n",
    "\n",
    "        if not isinstance(hyper_values, list):\n",
    "            return hyper_values\n",
    "\n",
    "        if not 'trial_suggest' in hyper_properties:\n",
    "            return hyper_values\n",
    "\n",
    "        trial_suggest = hyper_properties['trial_suggest']\n",
    "        return suggest_methods[trial_suggest](hyperparameter, trial,hyper_values)\n",
    "\n",
    "\n",
    "    def _get_hyperparameter_value(self, hyperparameter):\n",
    "        hyperparameters_dict = copy.deepcopy(self._hyper_possible_values)\n",
    "        if hyperparameter in hyperparameters_dict:\n",
    "            return hyperparameters_dict[hyperparameter]\n",
    "        return None"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
